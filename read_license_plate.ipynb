{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trained yolo model\n",
    "lp_detect_model = YOLO('yolo_model/best.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crop the license plate and save as image\n",
    "def crop_license_plates(img, yolo_model, save_img=True):\n",
    "    img_name = img.split(\"\\\\\")[-1]\n",
    "    \n",
    "    print(f\"Processing {img_name}\")\n",
    "    detected_lps = yolo_model.predict(img)[0]\n",
    "    license_plates = []\n",
    "    \n",
    "    for lp in detected_lps.boxes.data.tolist():\n",
    "        \n",
    "        x1, y1, x2, y2, conf, _ = lp\n",
    "       \n",
    "        img_array = cv2.imread(img)\n",
    "        cropped_lp =img_array[int(y1):int(y2), int(x1):int(x2), :]\n",
    "        license_plates.append(cropped_lp)\n",
    "        if save_img:\n",
    "            cv2.imwrite(f\"cropped_license_plates/cropped_{img_name}\", cropped_lp)\n",
    "        \n",
    "        \n",
    "    return license_plates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_dpi(image, target_dpi):\n",
    "    # Convert the NumPy array to Pillow image\n",
    "    pil_image = Image.fromarray(image)\n",
    "\n",
    "    # Calculate the scaling factor to achieve the target DPI\n",
    "    current_dpi = pil_image.info.get('dpi', (72, 72))  # Default DPI if not specified\n",
    "    scaling_factor = target_dpi / current_dpi[0]  # Assuming X and Y DPI are the same\n",
    "\n",
    "    # Calculate the new size based on the scaling factor\n",
    "    new_size = (int(pil_image.width * scaling_factor), int(pil_image.height * scaling_factor))\n",
    "\n",
    "    # Resize the image using Pillow\n",
    "    resized_image = pil_image.resize(new_size, resample=Image.LANCZOS)\n",
    "\n",
    "    # Set the DPI information\n",
    "    resized_image.info['dpi'] = (target_dpi, target_dpi)\n",
    "\n",
    "    # Convert the resized image back to a NumPy array\n",
    "    resized_array = np.array(resized_image)\n",
    "\n",
    "    return resized_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr(image):\n",
    "    custom_config = r'--psm 6 --oem 3 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZÃ–0123456789'\n",
    "    text = pytesseract.image_to_string(image, lang='deu', config=custom_config)\n",
    "    if text:\n",
    "        return text.strip(\"\\n\")\n",
    "    return \"not detected\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_license_plate(license_plate, name, save_img=True):\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    # grayscale\n",
    "    lp_gray = cv2.cvtColor(license_plate, cv2.COLOR_BGR2GRAY)\n",
    "    # erosion\n",
    "    lp_gray = cv2.erode(lp_gray, kernel, iterations=1)\n",
    "    # bilateral filter\n",
    "    lp_bilateral = cv2.bilateralFilter(lp_gray, 5, 75, 75)\n",
    "    # binary thresholding\n",
    "    _, lp_threshold = cv2.threshold(lp_bilateral, 6, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # contours in binary image\n",
    "    contours, _ = cv2.findContours(lp_threshold, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if not contours:\n",
    "        return None\n",
    "    # contour with largest area\n",
    "    max_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "    # Crop the license plate region\n",
    "    x, y, w, h = cv2.boundingRect(max_contour)\n",
    "    license_plate_cropped = lp_threshold[y:y + h, x:x + w]\n",
    "\n",
    "    # Rectify the license plate using perspective transformation\n",
    "    #rectified_plate = rectify_license_plate(license_plate_cropped)\n",
    "\n",
    "    if save_img:\n",
    "        cv2.imwrite(f'thresholded_license_plates/thresh_bil_rectified_{name}', license_plate_cropped)\n",
    "\n",
    "    return license_plate_cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read characters on licenese plate using OCR  \n",
    "def read_license_plates(license_plates,name, save_img=True):\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    for lp in license_plates:\n",
    "\n",
    "        #pre processing of the image:\n",
    "        \n",
    "        #1.    grayscale the image\n",
    "       \n",
    "        lp_gray = cv2.cvtColor(lp, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        #2.     erode the image\n",
    "        lp_gray = cv2.erode(lp_gray, kernel, iterations=1)\n",
    "\n",
    "        #3a.     remove noise with median filter\n",
    "        lp_median = cv2.medianBlur(lp_gray,5)\n",
    "        \n",
    "        #3b.     remove noise with bilateral filter\n",
    "        lp_bilateral = cv2.bilateralFilter(lp_gray, 5, 75, 75)\n",
    "\n",
    "        #4a.    canny edge detection \n",
    "        lp_canny = cv2.Canny(lp_median, 100, 200)\n",
    "\n",
    "        #4b.     binary thresholding \n",
    "        _, lp_threshold = cv2.threshold(lp_median, 6, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "        _, lp_threshold2 = cv2.threshold(lp_bilateral, 6, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "        if save_img:\n",
    "            cv2.imwrite(f'thresholded_license_plates/thresh_median_{name}', lp_threshold)\n",
    "            cv2.imwrite(f'thresholded_license_plates/thresh_bil_{name}', lp_threshold2)\n",
    "            cv2.imwrite(f'thresholded_license_plates/canny_{name}', lp_canny)\n",
    "\n",
    "        return lp_threshold, lp_threshold2, lp_canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image_1.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 e:\\Users\\belau\\Documents\\BV-ML-CV-Praktikum\\cam_frames\\image_1.jpg: 512x640 1 license_plate, 217.2ms\n",
      "Speed: 2.0ms preprocess, 217.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image_2.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 e:\\Users\\belau\\Documents\\BV-ML-CV-Praktikum\\cam_frames\\image_2.jpg: 512x640 1 license_plate, 168.9ms\n",
      "Speed: 2.0ms preprocess, 168.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image_3.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 e:\\Users\\belau\\Documents\\BV-ML-CV-Praktikum\\cam_frames\\image_3.jpg: 512x640 1 license_plate, 165.7ms\n",
      "Speed: 2.0ms preprocess, 165.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 e:\\Users\\belau\\Documents\\BV-ML-CV-Praktikum\\cam_frames\\image_4.jpg: 512x640 1 license_plate, 160.7ms\n",
      "Speed: 1.0ms preprocess, 160.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image_4.jpg\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image_5.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 e:\\Users\\belau\\Documents\\BV-ML-CV-Praktikum\\cam_frames\\image_5.jpg: 512x640 1 license_plate, 182.2ms\n",
      "Speed: 1.0ms preprocess, 182.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "path_to_cam_frames = 'cam_frames'\n",
    "res = []\n",
    "for f in os.listdir(path_to_cam_frames):\n",
    "    if f.endswith('.jpg') or f.endswith('.png'):\n",
    "        img = os.path.join(path_to_cam_frames, f)\n",
    "\n",
    "        test_lps = crop_license_plates(img, lp_detect_model)\n",
    "        print(len(test_lps))\n",
    "        median, bilateral, canny = read_license_plates(test_lps,f)\n",
    "        re_cropped = preprocess_license_plate(test_lps[0], f)\n",
    "        ocr_recrop = ocr(re_cropped)\n",
    "        ocr_median = ocr(median)\n",
    "        ocr_bilateral = ocr(bilateral)\n",
    "        ocr_canny = ocr(canny)\n",
    "        res.append([f[:-4], ocr_median, ocr_bilateral, ocr_canny, ocr_recrop])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0             1           2          3         4\n",
      "0  image_1     SHGALF2O6  ISHGRLF2O6  SWGRUGZUE  SHGLF2O6\n",
      "1  image_2      SHGLF2O6   ISHGLF2O6   SE8LEZOA  SHGLF2O6\n",
      "2  image_3  not detected    SHGLF2O6   SSCLEATS  SHGLF2O6\n",
      "3  image_4     SHGRLF2O6    SHGLF2O6  SHESUR2UE  SHGLF2O6\n",
      "4  image_5     SHGTLF286    SHGLF2O6  SHESUE2UA  SHGLF2O6\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "res = pd.DataFrame(res)\n",
    "print(res)\n",
    "res.to_csv(\"ocr_results.csv\", index=False, header=[\"Image name\", \"Canny\", \"Bilateral + Tresh\",\"Median + Tresh\", \"recropped\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
