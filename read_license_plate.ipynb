{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trained yolo model\n",
    "lp_detect_model = YOLO('yolo_model/best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crop the license plate and save as image\n",
    "def crop_license_plates(img, yolo_model, save_img=True):\n",
    "    img_name = img.split(\"\\\\\")[-1]\n",
    "    \n",
    "    print(f\"Processing {img_name}\")\n",
    "    detected_lps = yolo_model.predict(img)[0]\n",
    "    license_plates = []\n",
    "    \n",
    "    for lp in detected_lps.boxes.data.tolist():\n",
    "        \n",
    "        x1, y1, x2, y2, conf, _ = lp\n",
    "       \n",
    "        img_array = cv2.imread(img)\n",
    "        cropped_lp =img_array[int(y1):int(y2), int(x1):int(x2), :]\n",
    "        license_plates.append(cropped_lp)\n",
    "        if save_img:\n",
    "            cv2.imwrite(f\"cropped_license_plates/cropped_{img_name}\", cropped_lp)\n",
    "        \n",
    "        \n",
    "    return license_plates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_dpi(image, target_dpi):\n",
    "    # Convert the NumPy array to Pillow image\n",
    "    pil_image = Image.fromarray(image)\n",
    "\n",
    "    # Calculate the scaling factor to achieve the target DPI\n",
    "    current_dpi = pil_image.info.get('dpi', (72, 72))  # Default DPI if not specified\n",
    "    scaling_factor = target_dpi / current_dpi[0]  # Assuming X and Y DPI are the same\n",
    "\n",
    "    # Calculate the new size based on the scaling factor\n",
    "    new_size = (int(pil_image.width * scaling_factor), int(pil_image.height * scaling_factor))\n",
    "\n",
    "    # Resize the image using Pillow\n",
    "    resized_image = pil_image.resize(new_size, resample=Image.LANCZOS)\n",
    "\n",
    "    # Set the DPI information\n",
    "    resized_image.info['dpi'] = (target_dpi, target_dpi)\n",
    "\n",
    "    # Convert the resized image back to a NumPy array\n",
    "    resized_array = np.array(resized_image)\n",
    "\n",
    "    return resized_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr(image):\n",
    "    custom_config = r'--psm 6 --oem 3 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'\n",
    "    text = pytesseract.image_to_string(image, lang='deu', config=custom_config)\n",
    "    if text:\n",
    "        return text.strip(\"\\n\")\n",
    "    return \"not detected\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read characters on licenese plate using OCR  \n",
    "def read_license_plates(license_plates,name, save_img=True):\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    for lp in license_plates:\n",
    "\n",
    "        #pre processing of the image:\n",
    "        \n",
    "        #1.    grayscale the image\n",
    "       \n",
    "        lp_gray = cv2.cvtColor(lp, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        #2.     erode the image\n",
    "        lp_gray = cv2.erode(lp_gray, kernel, iterations=1)\n",
    "\n",
    "        #3a.     remove noise with median filter\n",
    "        lp_median = cv2.medianBlur(lp_gray,5)\n",
    "        \n",
    "        #3b.     remove noise with bilateral filter\n",
    "        lp_bilateral = cv2.bilateralFilter(lp_gray, 5, 75, 75)\n",
    "\n",
    "        #4a.    canny edge detection \n",
    "        lp_canny = cv2.Canny(lp_median, 100, 200)\n",
    "\n",
    "        #4b.     binary thresholding \n",
    "        _, lp_threshold = cv2.threshold(lp_median, 6, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "        _, lp_threshold2 = cv2.threshold(lp_bilateral, 6, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "        if save_img:\n",
    "            cv2.imwrite(f'thresholded_license_plates/thresh_median_{name}', lp_threshold)\n",
    "            cv2.imwrite(f'thresholded_license_plates/thresh_bil_{name}', lp_threshold2)\n",
    "            cv2.imwrite(f'thresholded_license_plates/canny_{name}', lp_canny)\n",
    "\n",
    "        return lp_threshold, lp_threshold2, lp_canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing cam_frames/image_2.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 e:\\Users\\belau\\Documents\\BV-ML-CV-Praktikum\\cam_frames\\image_2.jpg: 512x640 1 license_plate, 168.2ms\n",
      "Speed: 2.0ms preprocess, 168.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "test_lps = crop_license_plates('cam_frames/image_2.jpg', lp_detect_model)\n",
    "\n",
    "median, bilateral, canny = read_license_plates(test_lps,\"test.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image_1.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 e:\\Users\\belau\\Documents\\BV-ML-CV-Praktikum\\cam_frames\\image_1.jpg: 512x640 1 license_plate, 177.2ms\n",
      "Speed: 2.0ms preprocess, 177.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 e:\\Users\\belau\\Documents\\BV-ML-CV-Praktikum\\cam_frames\\image_2.jpg: 512x640 1 license_plate, 146.1ms\n",
      "Speed: 1.0ms preprocess, 146.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image_2.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 e:\\Users\\belau\\Documents\\BV-ML-CV-Praktikum\\cam_frames\\image_3.jpg: 512x640 1 license_plate, 143.1ms\n",
      "Speed: 1.0ms preprocess, 143.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image_3.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 e:\\Users\\belau\\Documents\\BV-ML-CV-Praktikum\\cam_frames\\image_4.jpg: 512x640 1 license_plate, 153.1ms\n",
      "Speed: 1.0ms preprocess, 153.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image_4.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 e:\\Users\\belau\\Documents\\BV-ML-CV-Praktikum\\cam_frames\\image_5.jpg: 512x640 1 license_plate, 146.1ms\n",
      "Speed: 1.0ms preprocess, 146.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image_5.jpg\n"
     ]
    }
   ],
   "source": [
    "path_to_cam_frames = 'cam_frames'\n",
    "res = []\n",
    "for f in os.listdir(path_to_cam_frames):\n",
    "    if f.endswith('.jpg') or f.endswith('.png'):\n",
    "        img = os.path.join(path_to_cam_frames, f)\n",
    "\n",
    "        test_lps = crop_license_plates(img, lp_detect_model)\n",
    "        median, bilateral, canny = read_license_plates(test_lps,f)\n",
    "        ocr_median = ocr(median)\n",
    "        ocr_bilateral = ocr(bilateral)\n",
    "        ocr_canny = ocr(canny)\n",
    "        res.append([f[:-4], ocr_median, ocr_bilateral, ocr_canny])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0             1           2          3\n",
      "0  image_1.jpg     SHGALF206  ISHGRLF206  SWGRUGZUE\n",
      "1  image_2.jpg      SHGLF206   ISHGLF206   SE8LEZOA\n",
      "2  image_3.jpg  not detected    SHGLF206   SSCLEATS\n",
      "3  image_4.jpg     SHGRLF206    SHGLF206  SHESUR20E\n",
      "4  image_5.jpg     SHGTLF206    SHGLF206  SHESUE20A\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "res = pd.DataFrame(res)\n",
    "print(res)\n",
    "res.to_csv(\"ocr_results.csv\", index=False, header=[\"Image name\", \"Canny\", \"Bilateral + Tresh\",\"Median + Tresh\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
